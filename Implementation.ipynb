{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8953e611",
   "metadata": {},
   "source": [
    "### Installing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e00c633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (4.53.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (3.12.14)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.7.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install datasets transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da0a5eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.14.1)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bea466c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a503f8715a46fc891711f0d0aa3a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Authenticating the huggng face to login\n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cef5f51",
   "metadata": {},
   "source": [
    "### Loading the dataset from the hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b896d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['exid', 'inputs', 'targets'],\n",
      "    num_rows: 17634\n",
      "})\n",
      "Total samples: 17634\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "domains = ['educational_institution']\n",
    "\n",
    "datasets = [load_dataset(\"neulab/wiki_asp\", domain, trust_remote_code=True)[\"train\"] for domain in domains]\n",
    "dataset = concatenate_datasets(datasets)\n",
    "\n",
    "print(dataset)\n",
    "print(\"Total samples:\", len(dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f321dcbb",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a99f0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c691b6604724065a5279ac217b4b376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Normalising inputs/targets:   0%|          | 0/17634 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty inputs: 0 | Empty targets: 783\n",
      "Inputs chars: min=13 p50=44650 p90=209941 max=2198917\n",
      "Targets chars: min=0 p50=1219 p90=4100 max=36039\n",
      "\n",
      "Sample INPUT:\n",
      " < EOT > the church of st . peter at the castle , later known as st . peter in the west or le bailey , was granted to st . fridewide ' s priory in 1122 . ( fn . 956 ) the living was held in plurality with st . ebbe ' s from 1913 to 1926 and with st . aldate ' s 1927 - 8 . in 1928 the church and its property were used for the foundation of st . peter ' s hall , later st . peter ' s college , and fro\n",
      "\n",
      "Sample TARGET:\n",
      " in 1320 , adam de brome was appointed rector of the church of st mary the virgin . along with the appointment , he was given the rectory house , st mary hall , on the high street . st mary hall was acquired by oriel college in 1326 . bedel hall , adjoining st mary ' s to the south , was given by bishop carpenter of worcester in 1455 . these two halls , along with st martin ' s hall , served as ann\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "def _merge_inputs(x):\n",
    "    # inputs can be a list of strings so joining them\n",
    "    if isinstance(x, list):\n",
    "        return \" \".join([str(s) for s in x]).strip()\n",
    "    return str(x).strip()\n",
    "\n",
    "def _merge_targets(t):\n",
    "    # targets can be the list of [aspect, summary] pairs OR strings\n",
    "    out = []\n",
    "    if isinstance(t, list):\n",
    "        for item in t:\n",
    "            if isinstance(item, (list, tuple)) and len(item) >= 2:\n",
    "                out.append(str(item[1]))\n",
    "            elif isinstance(item, str):\n",
    "                out.append(item)\n",
    "    else:\n",
    "        out.append(str(t))\n",
    "    return \" \".join(out).strip()\n",
    "\n",
    "def normalize_batch(batch):\n",
    "    inputs_text  = [_merge_inputs(x) for x in batch[\"inputs\"]]\n",
    "    targets_text = [_merge_targets(x) for x in batch[\"targets\"]]\n",
    "    return {\"inputs_text\": inputs_text, \"targets_text\": targets_text}\n",
    "\n",
    "normalized = dataset.map(normalize_batch, batched=True, desc=\"Normalising inputs/targets\")\n",
    "\n",
    "# basic empties check\n",
    "num_empty_src = sum(1 for x in normalized[\"inputs_text\"] if not x)\n",
    "num_empty_tgt = sum(1 for x in normalized[\"targets_text\"] if not x)\n",
    "print(f\"Empty inputs: {num_empty_src} | Empty targets: {num_empty_tgt}\")\n",
    "\n",
    "# quick length stats (characters)\n",
    "src_lens = np.array([len(x) for x in normalized[\"inputs_text\"]])\n",
    "tgt_lens = np.array([len(x) for x in normalized[\"targets_text\"]])\n",
    "def q(a, p): \n",
    "    i = int(len(a) * p)\n",
    "    return int(np.sort(a)[i])\n",
    "\n",
    "print(\n",
    "    f\"Inputs chars: min={src_lens.min()} \"\n",
    "    f\"p50={q(src_lens,0.5)} p90={q(src_lens,0.9)} max={src_lens.max()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Targets chars: min={tgt_lens.min()} \"\n",
    "    f\"p50={q(tgt_lens,0.5)} p90={q(tgt_lens,0.9)} max={tgt_lens.max()}\"\n",
    ")\n",
    "\n",
    "# one normalised example\n",
    "i = 0\n",
    "print(\"\\nSample INPUT:\\n\", normalized[i][\"inputs_text\"][:400])\n",
    "print(\"\\nSample TARGET:\\n\", normalized[i][\"targets_text\"][:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52742426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c928a77fa8548eaad6e1dc56b48d45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Cleaning text:   0%|          | 0/17634 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e09459482949be8311095879ef6059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Drop empty targets:   0%|          | 0/17634 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['exid', 'inputs', 'targets', 'source', 'summary'],\n",
      "    num_rows: 16813\n",
      "})\n",
      "Examples after cleaning: 16813\n",
      "Sample source: the church of st. peter at the castle, later known as st. peter in the west or le bailey, was granted to st. fridewide ' s priory in 1122. the living was held in plurality with st. ebbe ' s from 1913 to 1926 and with st. aldate ' s 1927 - 8. in 1928 the church and its property were used for the foun\n",
      "\n",
      "Sample summary: in 1320, adam de brome was appointed rector of the church of st mary the virgin. along with the appointment, he was given the rectory house, st mary hall, on the high street. st mary hall was acquired by oriel college in 1326. bedel hall, adjoining st mary ' s to the south, was given by bishop carpe\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from datasets import Dataset\n",
    "\n",
    "# cleaning the text\n",
    "RE_EOT = re.compile(r\"\\s*<\\s*EOT\\s*>\\s*\", re.IGNORECASE)\n",
    "RE_FOOTNOTE = re.compile(r\"\\(\\s*fn\\s*\\.\\s*\\d+\\s*\\)\", re.IGNORECASE)\n",
    "RE_SPACES = re.compile(r\"\\s+\")\n",
    "\n",
    "def tidy_punct(s: str) -> str:\n",
    "    # normalising the spaces around punctuation\n",
    "    s = re.sub(r\"\\s+([,.;:!?])\", r\"\\1\", s)\n",
    "    s = re.sub(r\"([(\\[])\\\\s+\",\"\\\\1\", s)\n",
    "    s = re.sub(r\"\\s+([)\\]])\", r\"\\1\", s)\n",
    "    return s\n",
    "\n",
    "def clean_str(s: str) -> str:\n",
    "    s = RE_EOT.sub(\" \", s)\n",
    "    s = RE_FOOTNOTE.sub(\" \", s)\n",
    "    s = RE_SPACES.sub(\" \", s).strip()\n",
    "    s = tidy_punct(s)\n",
    "    return s\n",
    "\n",
    "def clean_batch(batch):\n",
    "    src = [clean_str(x) for x in batch[\"inputs_text\"]]\n",
    "    tgt = [clean_str(x) for x in batch[\"targets_text\"]]\n",
    "    return {\"inputs_text\": src, \"targets_text\": tgt}\n",
    "\n",
    "cleaned = normalized.map(clean_batch, batched=True, desc=\"Cleaning text\")\n",
    "\n",
    "# dropping the entries with empty target after cleaning\n",
    "cleaned = cleaned.filter(lambda t: bool(t and t.strip()), input_columns=[\"targets_text\"], desc=\"Drop empty targets\")\n",
    "\n",
    "# deduplicating it by source text (exact match)\n",
    "seen = set()\n",
    "keep_idx = []\n",
    "for i, x in enumerate(cleaned[\"inputs_text\"]):\n",
    "    if x in seen:\n",
    "        continue\n",
    "    seen.add(x)\n",
    "    keep_idx.append(i)\n",
    "\n",
    "cleaned = cleaned.select(keep_idx)\n",
    "\n",
    "# renaming to the final column names\n",
    "cleaned = cleaned.rename_columns({\"inputs_text\": \"source\", \"targets_text\": \"summary\"})\n",
    "\n",
    "print(cleaned)\n",
    "print(\"Examples after cleaning:\", len(cleaned))\n",
    "print(\"Sample source:\", cleaned[0][\"source\"][:300])\n",
    "print(\"\\nSample summary:\", cleaned[0][\"summary\"][:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c36f18",
   "metadata": {},
   "source": [
    "### Loading the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f0f8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07cf81ee566a4e9292130e254eb09930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Measuring token lengths:   0%|          | 0/16813 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc87fe2c428407bb4cf5c0f718686b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering by token length:   0%|          | 0/16813 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['source_text', 'target_text'],\n",
      "    num_rows: 584\n",
      "})\n",
      "Total examples after filtering: 584\n",
      "\n",
      "Sample pair:\n",
      "SOURCE: summarize: support the friends of caerleon comprehensive school by joining our school lottery - all proceeds benefit the school. follow the link below: caerleon comprehensive school uses cookies to improve our website an\n",
      "\n",
      "TARGET: according to a 2016 estyn inspection, all students leaving at key stage 4 left with a recognized qualification. department for education performance tables reveal caerleon comprehensive ' s success record, with an averag\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Picking the base model\n",
    "BASE_CKPT = \"t5-base\"\n",
    "tok = AutoTokenizer.from_pretrained(BASE_CKPT, use_fast=True)\n",
    "\n",
    "def add_prefix(ex):\n",
    "    ex[\"source_text\"] = \"summarize: \" + ex[\"source\"]\n",
    "    ex[\"target_text\"] = ex[\"summary\"]\n",
    "    return ex\n",
    "\n",
    "with_prefix = cleaned.map(add_prefix, desc=\"Adding task prefix\")\n",
    "\n",
    "def add_lengths(ex):\n",
    "    # getting the token lengths without truncation so we can filter\n",
    "    ex[\"input_len\"]  = len(tok.encode(ex[\"source_text\"], truncation=False))\n",
    "    ex[\"target_len\"] = len(tok.encode(ex[\"target_text\"], truncation=False))\n",
    "    return ex\n",
    "\n",
    "with_lens = with_prefix.map(add_lengths, desc=\"Measuring token lengths\")\n",
    "\n",
    "# Reasonable bounds for T5/BART fine-tuning\n",
    "MIN_IN, MAX_IN = 32, 1024     # inputs between 32 and 1024 tokens\n",
    "MIN_OUT, MAX_OUT = 8, 200     # targets between 8 and 200 tokens\n",
    "\n",
    "filtered = with_lens.filter(\n",
    "    lambda il, tl: (MIN_IN <= il <= MAX_IN) and (MIN_OUT <= tl <= MAX_OUT),\n",
    "    input_columns=[\"input_len\",\"target_len\"],\n",
    "    desc=\"Filtering by token length\"\n",
    ")\n",
    "\n",
    "# Keeping only the final columns used for training \n",
    "cols_to_keep = [\"source_text\", \"target_text\"]\n",
    "processed = filtered.remove_columns([c for c in filtered.column_names if c not in cols_to_keep])\n",
    "\n",
    "print(processed)\n",
    "print(\"Total examples after filtering:\", len(processed))\n",
    "print(\"\\nSample pair:\")\n",
    "print(\"SOURCE:\", processed[0][\"source_text\"][:220])\n",
    "print(\"\\nTARGET:\", processed[0][\"target_text\"][:220])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89797563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['source_text', 'target_text'],\n",
      "    num_rows: 584\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['source_text', 'target_text'],\n",
      "        num_rows: 467\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['source_text', 'target_text'],\n",
      "        num_rows: 58\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['source_text', 'target_text'],\n",
      "        num_rows: 59\n",
      "    })\n",
      "})\n",
      "Counts: {'train': 467, 'validation': 58, 'test': 59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b6e4cd4ac944b1afafa3b54540690a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "809824d2224a4053aad919e72b323ef1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/58 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba6098c4a3142cc909f249434dd2b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/59 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved processed splits to: data/wikiasp_educational_institution_t5_prepared\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# current processed dataset is names as `processed`\n",
    "print(processed)\n",
    "\n",
    "# 80/10/10 split\n",
    "tmp = processed.train_test_split(test_size=0.20, seed=42, shuffle=True)\n",
    "val_test = tmp[\"test\"].train_test_split(test_size=0.50, seed=42)\n",
    "\n",
    "final_ds = DatasetDict({\n",
    "    \"train\": tmp[\"train\"],\n",
    "    \"validation\": val_test[\"train\"],\n",
    "    \"test\": val_test[\"test\"]\n",
    "})\n",
    "\n",
    "print(final_ds)\n",
    "print(\"Counts:\", {k: len(v) for k,v in final_ds.items()})\n",
    "\n",
    "# saving it for reuse\n",
    "save_dir = \"data/wikiasp_educational_institution_t5_prepared\"\n",
    "final_ds.save_to_disk(save_dir)\n",
    "print(f\"Saved processed splits to: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f88c439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (4.53.2)\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: peft in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (0.17.1)\n",
      "Requirement already satisfied: accelerate in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (1.9.0)\n",
      "Requirement already satisfied: evaluate in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (0.4.5)\n",
      "Requirement already satisfied: rouge-score in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets) (3.12.14)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from peft) (2.6.0)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from rouge-score) (2.3.1)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from requests->transformers) (2025.7.14)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from nltk->rouge-score) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from nltk->rouge-score) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Installing the required libraries\n",
    "pip install transformers datasets peft accelerate evaluate rouge-score sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99a4af3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.7.1\n",
      "  Using cached torch-2.7.1-cp310-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: torchvision==0.22.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio==2.7.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch==2.7.1) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch==2.7.1) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch==2.7.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch==2.7.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch==2.7.1) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch==2.7.1) (2024.6.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torchvision==0.22.1) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torchvision==0.22.1) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from sympy>=1.13.3->torch==2.7.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from jinja2->torch==2.7.1) (3.0.2)\n",
      "Using cached torch-2.7.1-cp310-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.1\n",
      "    Uninstalling torch-2.3.1:\n",
      "      Successfully uninstalled torch-2.3.1\n",
      "Successfully installed torch-2.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef698254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: transformers 4.44.2\n",
      "Uninstalling transformers-4.44.2:\n",
      "  Successfully uninstalled transformers-4.44.2\n",
      "Found existing installation: peft 0.11.1\n",
      "Uninstalling peft-0.11.1:\n",
      "  Successfully uninstalled peft-0.11.1\n",
      "Found existing installation: accelerate 0.34.2\n",
      "Uninstalling accelerate-0.34.2:\n",
      "  Successfully uninstalled accelerate-0.34.2\n",
      "Found existing installation: tokenizers 0.19.1\n",
      "Uninstalling tokenizers-0.19.1:\n",
      "  Successfully uninstalled tokenizers-0.19.1\n",
      "Found existing installation: sentencepiece 0.2.1\n",
      "Uninstalling sentencepiece-0.2.1:\n",
      "  Successfully uninstalled sentencepiece-0.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.44.2\n",
      "  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting peft==0.11.1\n",
      "  Using cached peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting accelerate==0.34.2\n",
      "  Using cached accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentencepiece>=0.1.99\n",
      "  Using cached sentencepiece-0.2.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: evaluate>=0.4.2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (0.4.6)\n",
      "Requirement already satisfied: rouge-score>=0.1.2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (0.1.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers==4.44.2) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers==4.44.2) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers==4.44.2) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers==4.44.2) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers==4.44.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers==4.44.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers==4.44.2) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers==4.44.2) (0.5.3)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n",
      "  Using cached tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers==4.44.2) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from peft==0.11.1) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from peft==0.11.1) (2.3.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.1.5)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from evaluate>=0.4.2) (3.0.1)\n",
      "Requirement already satisfied: dill in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from evaluate>=0.4.2) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from evaluate>=0.4.2) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from evaluate>=0.4.2) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from evaluate>=0.4.2) (0.70.16)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from rouge-score>=0.1.2) (2.3.1)\n",
      "Requirement already satisfied: nltk in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from rouge-score>=0.1.2) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from rouge-score>=0.1.2) (1.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate>=0.4.2) (21.0.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate>=0.4.2) (3.12.14)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate>=0.4.2) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate>=0.4.2) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate>=0.4.2) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate>=0.4.2) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate>=0.4.2) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate>=0.4.2) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate>=0.4.2) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate>=0.4.2) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets>=2.0.0->evaluate>=0.4.2) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from requests->transformers==4.44.2) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from requests->transformers==4.44.2) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from requests->transformers==4.44.2) (2025.7.14)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.11.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.11.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.11.1) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.11.1) (3.0.2)\n",
      "Requirement already satisfied: click in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from nltk->rouge-score>=0.1.2) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from nltk->rouge-score>=0.1.2) (1.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from pandas->evaluate>=0.4.2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from pandas->evaluate>=0.4.2) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from pandas->evaluate>=0.4.2) (2025.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.11.1) (1.3.0)\n",
      "Using cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\n",
      "Using cached peft-0.11.1-py3-none-any.whl (251 kB)\n",
      "Using cached accelerate-0.34.2-py3-none-any.whl (324 kB)\n",
      "Using cached tokenizers-0.19.1-cp310-cp310-macosx_11_0_arm64.whl (2.4 MB)\n",
      "Using cached sentencepiece-0.2.1-cp310-cp310-macosx_11_0_arm64.whl (1.3 MB)\n",
      "Installing collected packages: sentencepiece, tokenizers, accelerate, transformers, peft\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [peft][32m3/5\u001b[0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-0.34.2 peft-0.11.1 sentencepiece-0.2.1 tokenizers-0.19.1 transformers-4.44.2\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y transformers peft accelerate tokenizers sentencepiece\n",
    "!pip install --upgrade \"transformers==4.44.2\" \"peft==0.11.1\" \"accelerate==0.34.2\" \"sentencepiece>=0.1.99\" \"evaluate>=0.4.2\" \"rouge-score>=0.1.2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cfa257",
   "metadata": {},
   "source": [
    "### Model Fine tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1237fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import os\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d0e3b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/textsum/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data/wikiasp_educational_institution_t5_prepared\"\n",
    "ds = load_from_disk(data_dir)\n",
    "\n",
    "BASE_CKPT = \"t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_CKPT, use_fast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb276ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f1dedd08a94685a8fdc58dde529845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/467 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/textsum/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1074f741b6e547a8ad3269591f5e1ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/58 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1315e114d543fe9a3e642436cb7c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/59 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 467\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 58\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 59\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "MAX_SRC_LEN = 512\n",
    "MAX_TGT_LEN = 128\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    model_inputs = tokenizer(\n",
    "        batch[\"source_text\"],\n",
    "        max_length=MAX_SRC_LEN,\n",
    "        truncation=True\n",
    "    )\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(\n",
    "            batch[\"target_text\"],\n",
    "            max_length=MAX_TGT_LEN,\n",
    "            truncation=True\n",
    "        )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenised = ds.map(tokenize_fn, batched=True, remove_columns=[\"source_text\",\"target_text\"])\n",
    "print(tokenised)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "803b9f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa987b236ad84e55b5659b3a6c9ef6e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702951146571409892f98726b45e274f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 223,788,288 || trainable%: 0.3953\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(BASE_CKPT)\n",
    "\n",
    "# LoRA config (lightweight)\n",
    "lora_cfg = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\"q\", \"v\"],  # T5 attention proj names\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    ")\n",
    "model = get_peft_model(model, lora_cfg)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ef7c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    # decode\n",
    "    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    pred_str = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    scores = rouge.compute(predictions=pred_str, references=label_str, use_stemmer=True)\n",
    "    # returning the mean scores\n",
    "    return {k: round(v * 100, 2) for k, v in scores.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d3709f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/textsum/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "out_dir = \"runs/t5_base_lora_wikiasp_edu\"\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=out_dir,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=8,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=25,\n",
    "    predict_with_generate=True,          # now valid\n",
    "    generation_max_length=MAX_TGT_LEN,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rougeL\",\n",
    "    greater_is_better=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cd289e",
   "metadata": {},
   "source": [
    "#### Fine tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fab14657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70893d4b8b8c41b7bbf858dda222617c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/232 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/textsum/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.6906, 'grad_norm': 0.5308341979980469, 'learning_rate': 0.00018990825688073394, 'epoch': 0.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2194c5aabe34ed69185dad2501935f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 4.1148505210876465, 'eval_rouge1': 17.01, 'eval_rouge2': 3.91, 'eval_rougeL': 12.15, 'eval_rougeLsum': 12.27, 'eval_runtime': 66.0654, 'eval_samples_per_second': 0.878, 'eval_steps_per_second': 0.227, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/textsum/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.1243, 'grad_norm': 0.742151141166687, 'learning_rate': 0.0001669724770642202, 'epoch': 1.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c38b2adb3d646dd803d4e3d4d5daeaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.245060682296753, 'eval_rouge1': 16.65, 'eval_rouge2': 3.12, 'eval_rougeL': 12.28, 'eval_rougeLsum': 12.33, 'eval_runtime': 72.3691, 'eval_samples_per_second': 0.801, 'eval_steps_per_second': 0.207, 'epoch': 1.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/textsum/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5335, 'grad_norm': 0.3725351095199585, 'learning_rate': 0.00014403669724770643, 'epoch': 2.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7982fb36614b1a9bca0124d54ccb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.1606605052948, 'eval_rouge1': 16.18, 'eval_rouge2': 2.71, 'eval_rougeL': 12.5, 'eval_rougeLsum': 12.54, 'eval_runtime': 103.3355, 'eval_samples_per_second': 0.561, 'eval_steps_per_second': 0.145, 'epoch': 2.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/textsum/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4876, 'grad_norm': 0.4016471803188324, 'learning_rate': 0.00012110091743119268, 'epoch': 3.42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7857766e86b3447f9bd66a54fa3de032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.113563060760498, 'eval_rouge1': 16.93, 'eval_rouge2': 3.11, 'eval_rougeL': 13.62, 'eval_rougeLsum': 13.66, 'eval_runtime': 100.9025, 'eval_samples_per_second': 0.575, 'eval_steps_per_second': 0.149, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/textsum/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3707, 'grad_norm': 0.36423516273498535, 'learning_rate': 9.816513761467891e-05, 'epoch': 4.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b193883b0ae6484abfcb137747d436d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0894241333007812, 'eval_rouge1': 17.21, 'eval_rouge2': 2.93, 'eval_rougeL': 13.88, 'eval_rougeLsum': 13.88, 'eval_runtime': 99.9569, 'eval_samples_per_second': 0.58, 'eval_steps_per_second': 0.15, 'epoch': 4.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/textsum/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3505, 'grad_norm': 0.39099425077438354, 'learning_rate': 7.522935779816514e-05, 'epoch': 5.13}\n",
      "{'loss': 3.3411, 'grad_norm': 0.3913734555244446, 'learning_rate': 5.229357798165138e-05, 'epoch': 5.98}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade399405b4b4cc68170cd68a2adad4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0748965740203857, 'eval_rouge1': 17.71, 'eval_rouge2': 3.01, 'eval_rougeL': 14.43, 'eval_rougeLsum': 14.5, 'eval_runtime': 101.1773, 'eval_samples_per_second': 0.573, 'eval_steps_per_second': 0.148, 'epoch': 5.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/textsum/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3095, 'grad_norm': 0.4040462374687195, 'learning_rate': 2.9357798165137618e-05, 'epoch': 6.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24838a5e1f4243c1ac56674cd2b68723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.066894054412842, 'eval_rouge1': 18.45, 'eval_rouge2': 3.32, 'eval_rougeL': 14.92, 'eval_rougeLsum': 14.86, 'eval_runtime': 105.1372, 'eval_samples_per_second': 0.552, 'eval_steps_per_second': 0.143, 'epoch': 6.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/textsum/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.29, 'grad_norm': 0.4510098397731781, 'learning_rate': 6.422018348623854e-06, 'epoch': 7.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/textsum/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9e50bd051a407bbee24b4c64a11f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0646309852600098, 'eval_rouge1': 18.7, 'eval_rouge2': 3.26, 'eval_rougeL': 15.27, 'eval_rougeLsum': 15.26, 'eval_runtime': 117.9324, 'eval_samples_per_second': 0.492, 'eval_steps_per_second': 0.127, 'epoch': 7.93}\n",
      "{'train_runtime': 1470.1313, 'train_samples_per_second': 2.541, 'train_steps_per_second': 0.158, 'train_loss': 3.6029654782393883, 'epoch': 7.93}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=232, training_loss=3.6029654782393883, metrics={'train_runtime': 1470.1313, 'train_samples_per_second': 2.541, 'train_steps_per_second': 0.158, 'total_flos': 2249289612619776.0, 'train_loss': 3.6029654782393883, 'epoch': 7.931623931623932})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenised[\"train\"],\n",
    "    eval_dataset=tokenised[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e866ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/textsum/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ec43e398a44bedaea5b36cefcaecda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.085615396499634, 'eval_rouge1': 16.74, 'eval_rouge2': 2.74, 'eval_rougeL': 13.09, 'eval_rougeLsum': 13.14, 'eval_runtime': 123.3469, 'eval_samples_per_second': 0.478, 'eval_steps_per_second': 0.122, 'epoch': 7.931623931623932}\n",
      "\n",
      "SOURCE:\n",
      " summarize: western mst magnet high school is located in louisville, kentucky. scholarships for students attending western mst magnet high school can be found in our scholarship database. if you are searching for scholarships for students attending a different high school in louisville, visit the louisville directory. <EOS>\n",
      "\n",
      "SUMMARY:\n",
      " western mst magnet high school is located in louisville, kentucky.\n"
     ]
    }
   ],
   "source": [
    "print(trainer.evaluate(tokenised[\"test\"]))\n",
    "\n",
    "def generate(text, max_new_tokens=128):\n",
    "    enc = tokenizer(\"summarize: \" + text, return_tensors=\"pt\", truncation=True, max_length=MAX_SRC_LEN)\n",
    "    enc = {k: v.to(model.device) for k,v in enc.items()}\n",
    "    out = model.generate(**enc, max_new_tokens=max_new_tokens, num_beams=4)\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "sample_src = ds[\"test\"][0][\"source_text\"]\n",
    "print(\"\\nSOURCE:\\n\", sample_src[:800])\n",
    "print(\"\\nSUMMARY:\\n\", generate(sample_src))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1bab80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2c4c16",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7595d5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f65fb6ac49411c8f85785c791bf000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'eval_loss': 3.085615396499634, 'eval_rouge1': 16.74, 'eval_rouge2': 2.74, 'eval_rougeL': 13.09, 'eval_rougeLsum': 13.14, 'eval_runtime': 105.3595, 'eval_samples_per_second': 0.56, 'eval_steps_per_second': 0.142, 'epoch': 7.931623931623932}\n"
     ]
    }
   ],
   "source": [
    "test_metrics = trainer.evaluate(tokenised[\"test\"])\n",
    "print(\"Test metrics:\", test_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac4c441",
   "metadata": {},
   "source": [
    "#### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9abb8f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved adapter + tokenizer to: artifacts/t5_base_lora_wikiasp_edu\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"artifacts/t5_base_lora_wikiasp_edu\"\n",
    "model.save_pretrained(save_dir)         # saves LoRA adapter weights\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(\"Saved adapter + tokenizer to:\", save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2590bf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved merged full model to: artifacts/t5_base_merged_wikiasp_edu\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "merged_dir = \"artifacts/t5_base_merged_wikiasp_edu\"\n",
    "\n",
    "# reload base + adapter, then merge\n",
    "base = AutoModelForSeq2SeqLM.from_pretrained(BASE_CKPT)\n",
    "peft_loaded = PeftModel.from_pretrained(base, save_dir)\n",
    "\n",
    "merged = peft_loaded.merge_and_unload()     # folds LoRA weights into the base\n",
    "merged.save_pretrained(merged_dir)\n",
    "tokenizer.save_pretrained(merged_dir)\n",
    "\n",
    "print(\"Saved merged full model to:\", merged_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfa423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MERGED MODEL SUMMARY:\n",
      " western mst magnet high school is located in louisville, kentucky.\n",
      "\n",
      "ADAPTER MODEL SUMMARY:\n",
      " western mst magnet high school is located in louisville, kentucky.\n"
     ]
    }
   ],
   "source": [
    "sample = ds[\"test\"][0][\"source_text\"]\n",
    "\n",
    "# Using the merged model \n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tok_m = AutoTokenizer.from_pretrained(merged_dir)\n",
    "mdl_m = AutoModelForSeq2SeqLM.from_pretrained(merged_dir)\n",
    "\n",
    "enc = tok_m(\"summarize: \" + sample, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "out = mdl_m.generate(**enc, max_new_tokens=128, num_beams=4)\n",
    "print(\"\\nMERGED MODEL SUMMARY:\\n\", tok_m.decode(out[0], skip_special_tokens=True))\n",
    "\n",
    "# Using the adapter + base (PEFT) \n",
    "from peft import PeftModel\n",
    "tok_a = AutoTokenizer.from_pretrained(save_dir)\n",
    "base = AutoModelForSeq2SeqLM.from_pretrained(BASE_CKPT)\n",
    "mdl_a = PeftModel.from_pretrained(base, save_dir)\n",
    "\n",
    "enc = tok_a(\"summarize: \" + sample, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "out = mdl_a.generate(**enc, max_new_tokens=128, num_beams=4)\n",
    "print(\"\\nADAPTER MODEL SUMMARY:\\n\", tok_a.decode(out[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8117d954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (4.44.2)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (0.2.1)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from flask) (8.2.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from flask) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from flask) (3.0.2)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.1.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/textsum/lib/python3.10/site-packages (from requests->transformers) (2025.7.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install flask transformers torch sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2338ca6",
   "metadata": {},
   "source": [
    "## Web part Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "754e34e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from artifacts/t5_base_merged_wikiasp_edu on cpu...\n",
      "Model loaded successfully.\n",
      " * Serving Flask app 'app'\n",
      " * Debug mode: on\n",
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8000\n",
      " * Running on http://10.131.187.2:8000\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      " * Restarting with stat\n",
      "Loading model from artifacts/t5_base_merged_wikiasp_edu on cpu...\n",
      "Model loaded successfully.\n",
      " * Debugger is active!\n",
      " * Debugger PIN: 197-921-946\n",
      "127.0.0.1 - - [19/Oct/2025 00:15:58] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:16:13] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:16:43] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:16:43] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:17:35] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:17:37] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:17:37] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:17:47] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:18:18] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:18:57] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:18:57] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:19:26] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:20:12] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:20:12] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:20:39] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:21:08] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:21:08] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:21:19] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:22:03] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:22:03] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:22:15] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:22:39] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:22:39] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:22:49] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:24:22] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:25:07] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:25:07] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:25:18] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:26:51] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:26:51] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:27:02] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:27:25] \"\u001b[32mPOST / HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:27:25] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Oct/2025 00:27:55] \"POST / HTTP/1.1\" 200 -\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textsum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
